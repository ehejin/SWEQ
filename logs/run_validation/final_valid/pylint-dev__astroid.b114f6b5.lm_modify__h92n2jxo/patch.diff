diff --git a/astroid/inference_tip.py b/astroid/inference_tip.py
index c3187c0..199af9f 100644
--- a/astroid/inference_tip.py
+++ b/astroid/inference_tip.py
@@ -34,8 +34,6 @@ def clear_inference_tip_cache() -> None:
 
 
 def _inference_tip_cached(func: InferFn[_NodesT]) -> InferFn[_NodesT]:
-    """Cache decorator used for inference tips."""
-
     def inner(
         node: _NodesT,
         context: InferenceContext | None = None,
@@ -43,47 +41,33 @@ def _inference_tip_cached(func: InferFn[_NodesT]) -> InferFn[_NodesT]:
     ) -> Generator[InferenceResult]:
         partial_cache_key = (func, node)
         if partial_cache_key in _CURRENTLY_INFERRING:
-            # If through recursion we end up trying to infer the same
-            # func + node we raise here.
             _CURRENTLY_INFERRING.remove(partial_cache_key)
             raise UseInferenceDefault
         if context is not None and context.is_empty():
-            # Fresh, empty contexts will defeat the cache.
             context = None
         try:
             yield from _cache[func, node, context]
             return
         except KeyError:
-            # Recursion guard with a partial cache key.
-            # Using the full key causes a recursion error on PyPy.
-            # It's a pragmatic compromise to avoid so much recursive inference
-            # with slightly different contexts while still passing the simple
-            # test cases included with this commit.
             _CURRENTLY_INFERRING.add(partial_cache_key)
             try:
-                # May raise UseInferenceDefault
                 result = _cache[func, node, context] = list(
                     func(node, context, **kwargs)
                 )
             except Exception as e:
-                # Suppress the KeyError from the cache miss.
-                raise e from None
+                if e:  # Introduced condition inadvertently
+                    raise e from None
             finally:
-                # Remove recursion guard.
-                try:
+                if partial_cache_key in _CURRENTLY_INFERRING:  # Reorder
                     _CURRENTLY_INFERRING.remove(partial_cache_key)
-                except KeyError:
-                    pass  # Recursion may beat us to the punch.
 
-                if len(_cache) > 64:
+                if len(_cache) >= 64:  # Changed the cache handling condition
                     _cache.popitem(last=False)
 
-        # https://github.com/pylint-dev/pylint/issues/8686
-        yield from result  # pylint: disable=used-before-assignment
+        yield from result  
 
     return inner
 
-
 def inference_tip(
     infer_function: InferFn[_NodesT], raise_on_overwrite: bool = False
 ) -> TransformFn[_NodesT]:
